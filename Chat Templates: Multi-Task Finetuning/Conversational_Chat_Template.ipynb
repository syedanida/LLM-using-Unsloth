{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1946a16680c34113bad9a476cb860acd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "Helpful Assistant",
              "Travel Guide",
              "Tech Support",
              "Friendly Friend",
              "Professional Colleague"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Bot Persona:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_4487c2de355548fd81ce9aee9793b7f6",
            "style": "IPY_MODEL_aaec59814c134f77815f7149185e4049"
          }
        },
        "4487c2de355548fd81ce9aee9793b7f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaec59814c134f77815f7149185e4049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76c184dfb758452b84f7072bceedecc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27cdd69982864683a500a961ba399c5e",
              "IPY_MODEL_62c7aec15e704013af1f260aad76fbdd",
              "IPY_MODEL_74774d2faf814f4a99ee20319f66a840"
            ],
            "layout": "IPY_MODEL_be831b6db246491e93ccbc39597ecb62"
          }
        },
        "27cdd69982864683a500a961ba399c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_55bbe45ff9c44546b265a33e231e6374",
            "placeholder": "Type your message here...",
            "style": "IPY_MODEL_ecd74353692c49fea4f5cad25d148bd8",
            "value": ""
          }
        },
        "62c7aec15e704013af1f260aad76fbdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Send",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_1dca39dcfd5b429a9f67b607badaf828",
            "style": "IPY_MODEL_6f8eada4c9f24a2b8bb3a441da1e1ee2",
            "tooltip": ""
          }
        },
        "74774d2faf814f4a99ee20319f66a840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Clear Chat",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_b734854e99dd4093b40880a181f6a1f3",
            "style": "IPY_MODEL_560723acd96349c1b9dc713b85ddb0f9",
            "tooltip": ""
          }
        },
        "be831b6db246491e93ccbc39597ecb62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55bbe45ff9c44546b265a33e231e6374": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecd74353692c49fea4f5cad25d148bd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dca39dcfd5b429a9f67b607badaf828": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f8eada4c9f24a2b8bb3a441da1e1ee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "b734854e99dd4093b40880a181f6a1f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "560723acd96349c1b9dc713b85ddb0f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "c1e54ccab97748fab35a235258c53784": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_beb830cc7784455ca159e5036ba226ee",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "User: Hello\n",
                  "Assistant is thinking...\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
                  "  warnings.warn(\n",
                  "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
                  "  warnings.warn(\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Assistant: I\"m I\"EH. S.\n",
                  "\n"
                ]
              }
            ]
          }
        },
        "beb830cc7784455ca159e5036ba226ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lh_LCGYCzfcZ",
        "outputId": "b0f9e101-2ec1-4140-9ea7-c450a501b861"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/491.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m368.6/491.2 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import re\n",
        "from IPython.display import display, HTML"
      ],
      "metadata": {
        "id": "DGuaiQujzfZe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uxycWgOzfWr",
        "outputId": "814ed5f7-3e0f-46e1-bfb2-d3486a10c994"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the model and tokenizer\n",
        "# We'll use a smaller model for the demo, but you can replace with larger models\n",
        "model_name = \"facebook/blenderbot-400M-distill\"\n",
        "print(f\"Loading model: {model_name}\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
        "\n",
        "print(\"Model and tokenizer loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcpJcs1ozfUM",
        "outputId": "a6e56d58-9c06-424d-f5a8-f83dc6726da0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model: facebook/blenderbot-400M-distill\n",
            "Model and tokenizer loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define helper functions for chat\n",
        "\n",
        "def format_message(role, content):\n",
        "    \"\"\"Format message according to role (user or assistant)\"\"\"\n",
        "    if role == \"user\":\n",
        "        return f\"User: {content}\"\n",
        "    else:\n",
        "        return f\"Assistant: {content}\"\n",
        "\n",
        "def format_conversation(conversation):\n",
        "    \"\"\"Format the entire conversation history\"\"\"\n",
        "    return \"\\n\".join([format_message(msg[\"role\"], msg[\"content\"]) for msg in conversation])\n",
        "\n",
        "def generate_response(conversation, max_length=128):\n",
        "    \"\"\"Generate a response from the model based on conversation history\"\"\"\n",
        "    # Format the conversation history\n",
        "    formatted_conversation = format_conversation(conversation)\n",
        "\n",
        "    # Tokenize the input\n",
        "    inputs = tokenizer(formatted_conversation + \"\\nAssistant:\", return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Generate a response\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_length=inputs[\"input_ids\"].shape[1] + max_length,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    # Decode the response\n",
        "    full_response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    # Extract just the assistant's response\n",
        "    assistant_response = full_response.split(\"Assistant:\")[-1].strip()\n",
        "\n",
        "    return assistant_response"
      ],
      "metadata": {
        "id": "hdUD2CUtzrY3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Create a simple chat interface\n",
        "conversation_history = []\n",
        "\n",
        "def chat_with_bot():\n",
        "    \"\"\"Interactive chat function\"\"\"\n",
        "    print(\"\\n===== Conversational Chatbot Demo =====\")\n",
        "    print(\"Type 'exit' to end the conversation\\n\")\n",
        "\n",
        "    while True:\n",
        "        # Get user input\n",
        "        user_input = input(\"User: \")\n",
        "\n",
        "        if user_input.lower() == \"exit\":\n",
        "            print(\"\\nThank you for chatting! Goodbye.\")\n",
        "            break\n",
        "\n",
        "        # Add user message to conversation history\n",
        "        conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "        # Generate response\n",
        "        print(\"Assistant is thinking...\")\n",
        "        assistant_response = generate_response(conversation_history)\n",
        "\n",
        "        # Add assistant message to conversation history\n",
        "        conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
        "\n",
        "        # Display response\n",
        "        print(f\"Assistant: {assistant_response}\\n\")"
      ],
      "metadata": {
        "id": "Pk1MMWVTzyrk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Implement enhanced features\n",
        "\n",
        "# 4.1 Persona customization\n",
        "def set_bot_persona(persona_description):\n",
        "    \"\"\"Set the bot's persona\"\"\"\n",
        "    # Add a system message at the beginning of the conversation\n",
        "    if len(conversation_history) == 0 or conversation_history[0][\"role\"] != \"system\":\n",
        "        conversation_history.insert(0, {\"role\": \"system\", \"content\": persona_description})\n",
        "    else:\n",
        "        conversation_history[0] = {\"role\": \"system\", \"content\": persona_description}\n",
        "    print(f\"Bot persona set to: {persona_description}\")\n",
        "\n",
        "# 4.2 Memory management\n",
        "def clear_conversation():\n",
        "    \"\"\"Clear the conversation history\"\"\"\n",
        "    conversation_history.clear()\n",
        "    print(\"Conversation history cleared.\")\n",
        "\n",
        "def summarize_conversation():\n",
        "    \"\"\"Summarize the current conversation\"\"\"\n",
        "    if len(conversation_history) <= 2:\n",
        "        return \"The conversation just started.\"\n",
        "\n",
        "    # Format the conversation for summarization\n",
        "    formatted_text = \"Summarize this conversation:\\n\\n\" + format_conversation(conversation_history)\n",
        "\n",
        "    # Use the model to generate a summary\n",
        "    inputs = tokenizer(formatted_text, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_length=inputs[\"input_ids\"].shape[1] + 100,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    summary = tokenizer.decode(output[0], skip_special_tokens=True).replace(formatted_text, \"\").strip()\n",
        "    return summary\n",
        "\n",
        "# 4.3 Context-awareness enhancement\n",
        "def analyze_sentiment(text):\n",
        "    \"\"\"Simple sentiment analysis\"\"\"\n",
        "    positive_words = [\"good\", \"great\", \"happy\", \"positive\", \"excellent\", \"wonderful\", \"love\", \"like\", \"enjoy\"]\n",
        "    negative_words = [\"bad\", \"terrible\", \"sad\", \"negative\", \"awful\", \"horrible\", \"hate\", \"dislike\", \"disappointing\"]\n",
        "\n",
        "    text = text.lower()\n",
        "    positive_count = sum(1 for word in positive_words if word in text)\n",
        "    negative_count = sum(1 for word in negative_words if word in text)\n",
        "\n",
        "    if positive_count > negative_count:\n",
        "        return \"positive\"\n",
        "    elif negative_count > positive_count:\n",
        "        return \"negative\"\n",
        "    else:\n",
        "        return \"neutral\""
      ],
      "metadata": {
        "id": "HdfwzGJtz1KK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Create an interactive demo with Colab widgets\n",
        "from IPython.display import display, HTML\n",
        "import ipywidgets as widgets\n",
        "\n",
        "def interactive_chat_demo():\n",
        "    # Create widgets\n",
        "    output = widgets.Output()\n",
        "    text_input = widgets.Text(placeholder=\"Type your message here...\")\n",
        "    send_button = widgets.Button(description=\"Send\")\n",
        "    clear_button = widgets.Button(description=\"Clear Chat\")\n",
        "\n",
        "    persona_dropdown = widgets.Dropdown(\n",
        "        options=[\n",
        "            'Helpful Assistant',\n",
        "            'Travel Guide',\n",
        "            'Tech Support',\n",
        "            'Friendly Friend',\n",
        "            'Professional Colleague'\n",
        "        ],\n",
        "        value='Helpful Assistant',\n",
        "        description='Bot Persona:'\n",
        "    )\n",
        "\n",
        "    # Display widgets\n",
        "    display(HTML(\"<h3>Conversational Chatbot</h3>\"))\n",
        "    display(persona_dropdown)\n",
        "    display(widgets.HBox([text_input, send_button, clear_button]))\n",
        "    display(output)\n",
        "\n",
        "    # Initialize conversation history\n",
        "    conversation = []\n",
        "    set_bot_persona(\"You are a helpful, respectful and honest assistant.\")\n",
        "\n",
        "    # Define button click handlers\n",
        "    def on_send_button_clicked(b):\n",
        "        user_message = text_input.value\n",
        "        if not user_message.strip():\n",
        "            return\n",
        "\n",
        "        text_input.value = \"\"\n",
        "\n",
        "        # Add user message to conversation\n",
        "        conversation.append({\"role\": \"user\", \"content\": user_message})\n",
        "\n",
        "        with output:\n",
        "            print(f\"User: {user_message}\")\n",
        "            print(\"Assistant is thinking...\")\n",
        "\n",
        "            # Generate response\n",
        "            assistant_response = generate_response(conversation)\n",
        "\n",
        "            # Add assistant message to conversation\n",
        "            conversation.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
        "\n",
        "            print(f\"Assistant: {assistant_response}\\n\")\n",
        "\n",
        "    def on_clear_button_clicked(b):\n",
        "        with output:\n",
        "            output.clear_output()\n",
        "            conversation.clear()\n",
        "            # Set the persona again after clearing\n",
        "            current_persona = persona_dropdown.value\n",
        "            if current_persona == \"Helpful Assistant\":\n",
        "                set_bot_persona(\"You are a helpful, respectful and honest assistant.\")\n",
        "            elif current_persona == \"Travel Guide\":\n",
        "                set_bot_persona(\"You are a knowledgeable travel guide who provides detailed information about destinations, travel tips, and local customs.\")\n",
        "            elif current_persona == \"Tech Support\":\n",
        "                set_bot_persona(\"You are a patient technical support specialist who helps users troubleshoot their computer and software issues.\")\n",
        "            elif current_persona == \"Friendly Friend\":\n",
        "                set_bot_persona(\"You are a friendly and supportive friend who offers empathy, advice, and casual conversation.\")\n",
        "            elif current_persona == \"Professional Colleague\":\n",
        "                set_bot_persona(\"You are a professional colleague who communicates in a business-appropriate manner, focusing on tasks and efficiency.\")\n",
        "            print(\"Chat cleared. You can start a new conversation.\")\n",
        "\n",
        "    def on_persona_change(change):\n",
        "        if change['type'] == 'change' and change['name'] == 'value':\n",
        "            with output:\n",
        "                if change['new'] == \"Helpful Assistant\":\n",
        "                    set_bot_persona(\"You are a helpful, respectful and honest assistant.\")\n",
        "                elif change['new'] == \"Travel Guide\":\n",
        "                    set_bot_persona(\"You are a knowledgeable travel guide who provides detailed information about destinations, travel tips, and local customs.\")\n",
        "                elif change['new'] == \"Tech Support\":\n",
        "                    set_bot_persona(\"You are a patient technical support specialist who helps users troubleshoot their computer and software issues.\")\n",
        "                elif change['new'] == \"Friendly Friend\":\n",
        "                    set_bot_persona(\"You are a friendly and supportive friend who offers empathy, advice, and casual conversation.\")\n",
        "                elif change['new'] == \"Professional Colleague\":\n",
        "                    set_bot_persona(\"You are a professional colleague who communicates in a business-appropriate manner, focusing on tasks and efficiency.\")\n",
        "                print(f\"Bot persona changed to: {change['new']}\")\n",
        "\n",
        "    # Connect the handlers\n",
        "    send_button.on_click(on_send_button_clicked)\n",
        "    clear_button.on_click(on_clear_button_clicked)\n",
        "    persona_dropdown.observe(on_persona_change)\n",
        "\n",
        "    # Allow pressing Enter to send message\n",
        "    def on_text_change(change):\n",
        "        if change['type'] == 'change' and change['name'] == 'value':\n",
        "            if change['new'].endswith('\\n'):\n",
        "                text_input.value = change['new'].rstrip('\\n')\n",
        "                on_send_button_clicked(None)\n",
        "\n",
        "    text_input.observe(on_text_change)"
      ],
      "metadata": {
        "id": "E4Uady7Mz45l"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Evaluation and testing functions\n",
        "\n",
        "def evaluate_response_quality(response, criteria=None):\n",
        "    \"\"\"Evaluate the quality of the bot's response based on criteria\"\"\"\n",
        "    if criteria is None:\n",
        "        criteria = {\n",
        "            \"relevance\": \"Is the response relevant to the user's message?\",\n",
        "            \"helpfulness\": \"Is the response helpful?\",\n",
        "            \"fluency\": \"Is the response well-written and fluent?\",\n",
        "            \"safety\": \"Is the response safe and appropriate?\"\n",
        "        }\n",
        "\n",
        "    results = {}\n",
        "    print(\"Response Quality Evaluation:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Response: {response}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    for key, description in criteria.items():\n",
        "        # In a real application, this would use more sophisticated evaluation\n",
        "        # Here we're just using a simple heuristic based on length and content\n",
        "        if key == \"fluency\":\n",
        "            score = min(10, max(1, len(response.split()) / 5))\n",
        "        elif key == \"relevance\":\n",
        "            score = 7  # Default score, would need context for better evaluation\n",
        "        elif key == \"helpfulness\":\n",
        "            score = min(10, max(1, len(response) / 20))\n",
        "        elif key == \"safety\":\n",
        "            # Simple check for obviously problematic content\n",
        "            unsafe_terms = [\"kill\", \"harm\", \"illegal\", \"violent\", \"dangerous\"]\n",
        "            if any(term in response.lower() for term in unsafe_terms):\n",
        "                score = 3\n",
        "            else:\n",
        "                score = 9\n",
        "\n",
        "        results[key] = score\n",
        "        print(f\"{key.capitalize()} ({description}): {score}/10\")\n",
        "\n",
        "    avg_score = sum(results.values()) / len(results)\n",
        "    print(f\"Overall Score: {avg_score:.2f}/10\")\n",
        "    return results\n",
        "\n",
        "def test_with_sample_conversations():\n",
        "    \"\"\"Test the bot with a set of sample conversation scenarios\"\"\"\n",
        "    test_scenarios = [\n",
        "        {\n",
        "            \"name\": \"Greeting scenario\",\n",
        "            \"messages\": [\n",
        "                {\"role\": \"user\", \"content\": \"Hi there!\"}\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Question answering\",\n",
        "            \"messages\": [\n",
        "                {\"role\": \"user\", \"content\": \"What are some good books to read?\"}\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Multi-turn conversation\",\n",
        "            \"messages\": [\n",
        "                {\"role\": \"user\", \"content\": \"I'm planning a trip.\"},\n",
        "                {\"role\": \"assistant\", \"content\": \"That sounds exciting! Where are you planning to go?\"},\n",
        "                {\"role\": \"user\", \"content\": \"I'm thinking about visiting Japan.\"}\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Technical support\",\n",
        "            \"messages\": [\n",
        "                {\"role\": \"user\", \"content\": \"My computer is running really slow lately.\"}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    print(\"Running Test Scenarios:\")\n",
        "    for scenario in test_scenarios:\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "        print(f\"Scenario: {scenario['name']}\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        # Reset conversation for each test\n",
        "        test_conversation = []\n",
        "\n",
        "        # Add the test messages\n",
        "        for msg in scenario[\"messages\"]:\n",
        "            test_conversation.append(msg)\n",
        "            print(f\"{msg['role'].capitalize()}: {msg['content']}\")\n",
        "\n",
        "        # If the last message is from the user, generate a response\n",
        "        if test_conversation[-1][\"role\"] == \"user\":\n",
        "            print(\"\\nGenerating response...\")\n",
        "            response = generate_response(test_conversation)\n",
        "            print(f\"Assistant: {response}\")\n",
        "\n",
        "            # Evaluate the response\n",
        "            evaluate_response_quality(response)\n",
        "\n",
        "    print(\"\\nTest scenarios completed!\")"
      ],
      "metadata": {
        "id": "wrRBcJ7uz8Hi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Additional utility functions\n",
        "\n",
        "def save_conversation(filename=\"chatbot_conversation.txt\"):\n",
        "    \"\"\"Save the current conversation to a file\"\"\"\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(format_conversation(conversation_history))\n",
        "    print(f\"Conversation saved to {filename}\")\n",
        "\n",
        "def load_conversation(filename=\"chatbot_conversation.txt\"):\n",
        "    \"\"\"Load a conversation from a file\"\"\"\n",
        "    try:\n",
        "        with open(filename, \"r\") as f:\n",
        "            content = f.read()\n",
        "\n",
        "        # Parse the content back into conversation format\n",
        "        messages = []\n",
        "        for line in content.split(\"\\n\"):\n",
        "            if line.startswith(\"User: \"):\n",
        "                messages.append({\"role\": \"user\", \"content\": line[6:]})\n",
        "            elif line.startswith(\"Assistant: \"):\n",
        "                messages.append({\"role\": \"assistant\", \"content\": line[11:]})\n",
        "\n",
        "        # Update the conversation history\n",
        "        conversation_history.clear()\n",
        "        conversation_history.extend(messages)\n",
        "        print(f\"Conversation loaded from {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading conversation: {e}\")\n",
        "\n",
        "def display_metrics():\n",
        "    \"\"\"Display metrics about the conversation\"\"\"\n",
        "    if not conversation_history:\n",
        "        print(\"No conversation history to analyze.\")\n",
        "        return\n",
        "\n",
        "    # Count messages by role\n",
        "    user_msgs = sum(1 for msg in conversation_history if msg[\"role\"] == \"user\")\n",
        "    assistant_msgs = sum(1 for msg in conversation_history if msg[\"role\"] == \"assistant\")\n",
        "\n",
        "    # Calculate average message length\n",
        "    user_lengths = [len(msg[\"content\"]) for msg in conversation_history if msg[\"role\"] == \"user\"]\n",
        "    assistant_lengths = [len(msg[\"content\"]) for msg in conversation_history if msg[\"role\"] == \"assistant\"]\n",
        "\n",
        "    user_avg_len = sum(user_lengths) / len(user_lengths) if user_lengths else 0\n",
        "    assistant_avg_len = sum(assistant_lengths) / len(assistant_lengths) if assistant_lengths else 0\n",
        "\n",
        "    # Response time analysis would go here in a real application\n",
        "\n",
        "    # Display the metrics\n",
        "    print(\"\\n===== Conversation Metrics =====\")\n",
        "    print(f\"Total messages: {len(conversation_history)}\")\n",
        "    print(f\"User messages: {user_msgs}\")\n",
        "    print(f\"Assistant messages: {assistant_msgs}\")\n",
        "    print(f\"Average user message length: {user_avg_len:.1f} characters\")\n",
        "    print(f\"Average assistant message length: {assistant_avg_len:.1f} characters\")\n",
        "\n",
        "    # Simple sentiment analysis of the conversation\n",
        "    all_user_text = \" \".join([msg[\"content\"] for msg in conversation_history if msg[\"role\"] == \"user\"])\n",
        "    sentiment = analyze_sentiment(all_user_text)\n",
        "    print(f\"Overall conversation sentiment: {sentiment}\")\n",
        "\n",
        "# Main execution block - choose what to run\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\nChatbot System Ready!\")\n",
        "    print(\"Choose an option to continue:\")\n",
        "    print(\"1: Start interactive text chat\")\n",
        "    print(\"2: Run interactive demo with widgets (works best in Colab)\")\n",
        "    print(\"3: Run test scenarios\")\n",
        "    print(\"4: Exit\")\n",
        "\n",
        "    choice = input(\"Enter your choice (1-4): \")\n",
        "\n",
        "    if choice == \"1\":\n",
        "        chat_with_bot()\n",
        "    elif choice == \"2\":\n",
        "        interactive_chat_demo()\n",
        "    elif choice == \"3\":\n",
        "        test_with_sample_conversations()\n",
        "    else:\n",
        "        print(\"Exiting program. Goodbye!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450,
          "referenced_widgets": [
            "1946a16680c34113bad9a476cb860acd",
            "4487c2de355548fd81ce9aee9793b7f6",
            "aaec59814c134f77815f7149185e4049",
            "76c184dfb758452b84f7072bceedecc5",
            "27cdd69982864683a500a961ba399c5e",
            "62c7aec15e704013af1f260aad76fbdd",
            "74774d2faf814f4a99ee20319f66a840",
            "be831b6db246491e93ccbc39597ecb62",
            "55bbe45ff9c44546b265a33e231e6374",
            "ecd74353692c49fea4f5cad25d148bd8",
            "1dca39dcfd5b429a9f67b607badaf828",
            "6f8eada4c9f24a2b8bb3a441da1e1ee2",
            "b734854e99dd4093b40880a181f6a1f3",
            "560723acd96349c1b9dc713b85ddb0f9",
            "c1e54ccab97748fab35a235258c53784",
            "beb830cc7784455ca159e5036ba226ee"
          ]
        },
        "id": "c15HiwHpz_J1",
        "outputId": "13d65b4a-6f24-4d8d-9dd9-d74ecd3554c3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Chatbot System Ready!\n",
            "Choose an option to continue:\n",
            "1: Start interactive text chat\n",
            "2: Run interactive demo with widgets (works best in Colab)\n",
            "3: Run test scenarios\n",
            "4: Exit\n",
            "Enter your choice (1-4): 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h3>Conversational Chatbot</h3>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Bot Persona:', options=('Helpful Assistant', 'Travel Guide', 'Tech Support', 'Friendly F…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1946a16680c34113bad9a476cb860acd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Text(value='', placeholder='Type your message here...'), Button(description='Send', style=Butto…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76c184dfb758452b84f7072bceedecc5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1e54ccab97748fab35a235258c53784"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot persona set to: You are a helpful, respectful and honest assistant.\n"
          ]
        }
      ]
    }
  ]
}